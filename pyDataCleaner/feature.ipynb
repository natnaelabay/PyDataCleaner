{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spectacular-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "grave-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_regression(\n",
    "    n_samples=1000, \n",
    "    n_features=100, \n",
    "    n_informative=10, \n",
    "    noise=0.1,\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "increasing-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vital-concrete",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (670, 100) (670,)\n",
      "Test (330, 100) (330,)\n"
     ]
    }
   ],
   "source": [
    "print('Train', x_train.shape, y_train.shape)\n",
    "print('Test', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-camcorder",
   "metadata": {
    "tags": [
     "introduction"
    ]
   },
   "source": [
    "## Correlation and Mutual Information Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "careful-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from matplotlib import pyplot as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fallen-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def numerical_feature_selection(df, labels, test_size, percentage, k, selection_function=f_regression):\n",
    "    '''\n",
    "    params: \n",
    "        `df`: DataFrame\n",
    "        `test_size` : test_size from 0 - 1\n",
    "        `percentage` : train and test spliting percentage\n",
    "        `k` : number of features that will be selected\n",
    "        `selection_function` : A selection function if not provided default is f_regression/mutual_info_regression from the `sklearn.feature_selection` module. \n",
    "        `labels` : list of column names that the model will try to predict\n",
    "    '''\n",
    "    features = [col for col in df.columns.values if col not in labels]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        df[features],\n",
    "        df[labels],\n",
    "        test_size=test_size\n",
    "    )\n",
    "\n",
    "    fs = SelectKBest(\n",
    "        score_func=selection_function,\n",
    "        k=k\n",
    "    )\n",
    "\n",
    "    fs.fit(x_train, y_train)\n",
    "    x_train_fs = fs.transform(x_train)\n",
    "    x_test_fs = fs.transform(x_test)\n",
    "    pt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "    return x_train_fs, x_test_fs, y_train, y_test\n",
    "\n",
    "\n",
    "def test_regression_model(\n",
    "    x_train_ts,\n",
    "    x_test_ts,\n",
    "    y_train,\n",
    "    y_test,\n",
    "):\n",
    "    '''\n",
    "    This methods tests a data set with a regression model\n",
    "    '''\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train_ts, y_train)\n",
    "    y_pred = model.predict(x_test_ts)\n",
    "    print('MAE(Mean Absolute Error): ', mean_absolute_error(y_test, y_pred))\n",
    "    print('MSE(Mean Squared Error): ', mean_squared_error(y_test, y_pred))\n",
    "    return model\n",
    "\n",
    "\n",
    "# def tune_features():\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-stroke",
   "metadata": {},
   "source": [
    "# Categorical Input Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "noble-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def categorical_feature_selection(\n",
    "    df: pd.DataFrame,\n",
    "    labels,\n",
    "    test_size,\n",
    "):\n",
    "    '''\n",
    "    This method will select categorical features\n",
    "    '''\n",
    "    from sklearn.feature_selection import SelectKBest, chi2\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "    features = [col for col in df.columns.values if col not in labels]\n",
    "\n",
    "    features_df = df[features].astype(str)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        features_df,\n",
    "        df[labels],\n",
    "        test_size=test_size\n",
    "    )\n",
    "\n",
    "    # encode input features/data\n",
    "\n",
    "    encoder = OrdinalEncoder()\n",
    "    encoder.fit(x_train)\n",
    "    x_train_encoded = encoder.transform(x_train)\n",
    "    x_test_encoded = encoder.transform(x_test)\n",
    "\n",
    "    # encode target variables using LabelEncoder\n",
    "\n",
    "    le_encoder = LabelEncoder()\n",
    "    le_encoder.fit(y_train)\n",
    "\n",
    "    y_train_encoded = le_encoder.transform(y_train)\n",
    "    y_test_encoded = le_encoder.transform(y_test)\n",
    "\n",
    "    return x_train_encoded, x_test_encoded, y_train_encoded, y_test_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-cheat",
   "metadata": {},
   "source": [
    "## For categorical feature selection there are two techniques that can be used\n",
    "1. Chi-Squared Statistic\n",
    "2. Mutual Information Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quantitative-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi-squared method\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as pt\n",
    "\n",
    "\n",
    "def categorical_feature_selection(\n",
    "    df: pd.DataFrame,\n",
    "    labels,\n",
    "    test_size,\n",
    "    selection_func,\n",
    "    k=\"all\",\n",
    "):\n",
    "    '''\n",
    "    This method will select categorical features\n",
    "    '''\n",
    "    from sklearn.feature_selection import SelectKBest, chi2\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "    features = [col for col in df.columns.values if col not in labels]\n",
    "\n",
    "    features_df = df[features].astype(str)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        features_df,\n",
    "        df[labels],\n",
    "        test_size=test_size\n",
    "    )\n",
    "\n",
    "    # encode input features/data\n",
    "\n",
    "    encoder = OrdinalEncoder()\n",
    "    encoder.fit(x_train)\n",
    "    x_train_encoded = encoder.transform(x_train)\n",
    "    x_test_encoded = encoder.transform(x_test)\n",
    "\n",
    "    # encode target variables using LabelEncoder\n",
    "\n",
    "    le_encoder = LabelEncoder()\n",
    "    le_encoder.fit(y_train)\n",
    "\n",
    "    y_train_encoded = le_encoder.transform(y_train)\n",
    "    y_test_encoded = le_encoder.transform(y_test)\n",
    "\n",
    "    # 1. Mutual information feature with (mutual_info_classif)\n",
    "    # 2. Mutual information feature with chi-squared (chi2)\n",
    "    \n",
    "    fs = SelectKBest(\n",
    "        score_func=selection_func,\n",
    "        k=k\n",
    "    )\n",
    "\n",
    "    fs.fit(x_train_encoded, y_train_encoded)\n",
    "    x_train_fs = fs.transform(x_train_encoded)\n",
    "    x_test_fs = fs.transform(x_test_encoded)\n",
    "\n",
    "    pt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "    pt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    return x_train_fs, x_test_fs, fs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def numerical_feature_selector_with_categorical_target(\n",
    "    \n",
    "):\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "composed-darwin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -26.860 (2.704)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rfe_for_regression(\n",
    "    x_train_ts,\n",
    "    x_test_ts,\n",
    "):\n",
    "    '''\n",
    "    This method will test the model with the test data set\n",
    "    '''\n",
    "\n",
    "    from numpy import mean\n",
    "    from numpy import std\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.model_selection import RepeatedKFold\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.feature_selection import RFE\n",
    "\n",
    "    rfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=5)\n",
    "    model = DecisionTreeRegressor()\n",
    "    pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # evaluate model\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(\n",
    "        pipeline, \n",
    "        X, \n",
    "        y, \n",
    "        scoring='neg_mean_absolute_error', \n",
    "        cv=cv,\n",
    "    n_jobs=-1)\n",
    "    # report performance\n",
    "    print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "\n",
    "    return model\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "ref_for_regression(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-command",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
